<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"happylinzy.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Perspectives on Gradient Descent When talking about numerical solution to optimization problems, nobody can avoid the gradient descent method created by Cauchy in 1847. In this blog, we try to underst">
<meta property="og:type" content="article">
<meta property="og:title" content="Optimization I - Gradient Descent">
<meta property="og:url" content="https://happylinzy.github.io/2023/02/04/gd1/index.html">
<meta property="og:site_name" content="Yilin Blog">
<meta property="og:description" content="Perspectives on Gradient Descent When talking about numerical solution to optimization problems, nobody can avoid the gradient descent method created by Cauchy in 1847. In this blog, we try to underst">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-02-04T20:30:36.000Z">
<meta property="article:modified_time" content="2023-02-19T05:00:41.751Z">
<meta property="article:author" content="Yilin Zhang">
<meta property="article:tag" content="optimization, gradient methods">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://happylinzy.github.io/2023/02/04/gd1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Optimization I - Gradient Descent | Yilin Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Yilin Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://happylinzy.github.io/2023/02/04/gd1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yilin Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yilin Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Optimization I - Gradient Descent
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-02-04 12:30:36" itemprop="dateCreated datePublished" datetime="2023-02-04T12:30:36-08:00">2023-02-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-02-18 21:00:41" itemprop="dateModified" datetime="2023-02-18T21:00:41-08:00">2023-02-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/math/" itemprop="url" rel="index"><span itemprop="name">math</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="perspectives-on-gradient-descent">Perspectives on Gradient Descent</h1>
<p>When talking about numerical solution to optimization problems, nobody can avoid the gradient descent method created by Cauchy in 1847. In this blog, we try to understand this first order algorithm through different perspectives. <span class="math display">\[
x_{k+1} = x_{k} - \alpha \nabla f(x_k)
\]</span></p>
<span id="more"></span>
<h2 id="problem-formulation">Problem Formulation</h2>
<p>An optimization problem is trying to find the minimum value of a given function under constraints. <span class="math display">\[\begin{align*}
\min f(x)
\\
s.t. \ \ x \in \mathcal{M}
\end{align*}\]</span></p>
<p>Assumptions on <span class="math inline">\(f\)</span>:</p>
<p><span class="math inline">\(f\)</span> is convex</p>
<p><span class="math inline">\(f\)</span> is differentiable, <span class="math inline">\(f \in C^1\)</span></p>
<p><span class="math inline">\(f\)</span> is Lipschitz gradient continuous</p>
<h2 id="proximal-view">Proximal View</h2>
<p>Given an initial value <span class="math inline">\(x_0\)</span>, it is almost impossible to explictly express optimal <span class="math inline">\(x^*\)</span> as formula of <span class="math inline">\(x_0\)</span>, which means globally we don't know the relatino between <span class="math inline">\(x^*\)</span> and <span class="math inline">\(x_0\)</span>. But we can find a local optimal point which is better than <span class="math inline">\(x_0\)</span>. Then hopefully we can keep this process until we reach the <span class="math inline">\(x^*\)</span>.</p>
<p>For point <span class="math inline">\(x_k\)</span>, we have local approximation of <span class="math inline">\(f(x)\)</span> near <span class="math inline">\(x_k\)</span> according to Taylor series. <span class="math display">\[
f(x) = f(x_k) + \langle \nabla f(x_k), (x - x_k) \rangle + \frac{1}{2} \nabla^2 (x - x_k)^Tf(x_k)(x - x_k) + O(x^3)
\]</span></p>
<p>Here we take first order approximation of <span class="math inline">\(f(x)\)</span> since our assumption only guarantees that <span class="math inline">\(f(x)\)</span> is differentiable. Then we have local optimization problem as</p>
<p><span class="math display">\[\begin{align*}
\min \ &amp;f(x_k) + \langle \nabla f(x_k), (x - x_k) \rangle
\\
s.t. \ \ &amp;x \in \mathcal{M}
\\
&amp;x \in B_\epsilon(x_k)
\end{align*}\]</span></p>
<p>The constraint <span class="math inline">\(x \in B_\epsilon(x_k)\)</span> gurantees that our local optimal <span class="math inline">\(x\)</span> is local. Naturally we consider the point <span class="math inline">\(x\)</span> in Euclidean space with norm <span class="math inline">\(\frac{1}{2}||\cdot||^2\)</span>. This means the <span class="math inline">\(x \in B_\epsilon(x_k)\)</span> is <span class="math inline">\(||x - x_k||^2 = \epsilon\)</span></p>
<p>Then the Lagrangian of above local optimization is <span class="math display">\[
\mathcal{L} = f(x_k) + \langle \nabla f(x_k), (x - x_k) \rangle - \beta ||x - x_k||^2 + \beta \cdot \epsilon
\]</span> Let <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial x} = 0\)</span> we get</p>
<p><span class="math display">\[\begin{align*}
&amp; \nabla f(x_k) = -2\beta (x - x_k)
\\
\Rightarrow &amp; x = x_k - \frac{1}{2\beta}\nabla f(x_k)
\end{align*}\]</span></p>
<p>We choose <span class="math inline">\(\beta = \frac{1}{2\alpha}\)</span> we can get local explict optimal solution as <span class="math inline">\(x_{k+1}\)</span>.</p>
<p>In local proximal view, gradient descent is derived as local optimal solution in <span class="math inline">\(l_2\)</span> norm space with first order Taylor approximation.</p>
<h2 id="geometry-view">Geometry View</h2>
<p>Suppose that readers are familiar with differential geometry, we can see some hidden facts in gradient descent. Rewrite the formula as <span class="math display">\[
x_{k+1} - x_k = -\alpha \nabla f(x_k)
\]</span> The left hand side of above equation is cotravariant and right hand side is covariant (under a change of coordinate system). If we change the parametrization of <span class="math inline">\(f\)</span> from <span class="math inline">\(x\)</span> to <span class="math inline">\(\eta\)</span>, the gradient descent may lead to a different optimal value. Fortunately, this problem will not happen in <span class="math inline">\(l_2\)</span> norm Euclidean space. To state the reason, we need help of differential geometry.</p>
<p>Consider the Riemannian manifold <span class="math inline">\(\mathcal{M}\)</span> of point <span class="math inline">\(x\)</span>, the tangent space at <span class="math inline">\(x\)</span> is denoted as <span class="math inline">\(T_xM\)</span>. Then a natural idea is find the steepest direction in <span class="math inline">\(T_xM\)</span> and decent <span class="math inline">\(x\)</span> along the geodesic on that direction. With the help of Riemannian gradient we have <span class="math display">\[
    x_{k+1} = exp_{x_k}(-\alpha \cdot grad \ f(x_k))
\]</span> Generaly, the exponential map is hard to calculate, where we use retraction map to approximate it. <span class="math display">\[
    x_{k+1} = R_{x_k}(-\alpha \cdot grad \ f(x_k))
\]</span> One of the retraction choice is local first order approximation <span class="math inline">\(R_{x_k}(v) = x_k + v\)</span>. Therefore, we have <span class="math display">\[
    x_{k+1} = x_k -\alpha \cdot grad \ f(x_k)
\]</span> Here the Riemannian gradient is different with normal gradient. It operates on function value with a Riemannian metric <span class="math inline">\(g\)</span>. <span class="math display">\[
    x_{k+1} = x_k -\alpha g^{-1} \nabla f(x_k)
\]</span> In Euclidean space with norm <span class="math inline">\(l_2\)</span>, the Riemannian metric is identity matrix <span class="math inline">\(g = I\)</span>. From a geometric view, gradient descent is a special case of Riemanniam descent in Euclidean space where Riemannan matric is identity.</p>
<h2 id="dynamic-view">Dynamic View</h2>
<p>In dynamic view, we try to understand gradient descent as a physical system. Consider the <span class="math inline">\(x_k\)</span> as a sample of a curve at time <span class="math inline">\(t\)</span> with step size <span class="math inline">\(\delta\)</span>, which means <span class="math inline">\(t = \delta k\)</span>. Then we get <span class="math inline">\(X_t = X_{\delta k} = x_k\)</span>.</p>
<p>Then we have the Talyor series to connect <span class="math inline">\(x_k\)</span> and <span class="math inline">\(x_{k+1}\)</span>. <span class="math display">\[
x_{k+1} = X_{\delta k + \delta} = X_{t + \delta} = X_t + \dot{X_t} \delta + \ddot{X_t}\frac{\delta^2}{2} + O(\delta^3)
\]</span></p>
<p>Plug in the form of gradient descent we have <span class="math display">\[
 \dot{X_t} \delta + \ddot{X_t}\frac{\delta^2}{2} + O(\delta^3) = - \alpha \nabla f(X_t)
\]</span> Omit <span class="math inline">\(O(\delta^2)\)</span> item, let <span class="math inline">\(\delta = \alpha\)</span> scale, we have <span class="math display">\[\begin{align*}
    &amp; \dot{X} = - \nabla f(X)
\\
\Leftrightarrow &amp;\lim_{m \rightarrow 0}  m \ddot{X} + \dot{X} + \nabla f(X) = 0
\end{align*}\]</span> which accounts to a massless particle damping equation. The equation can be viewed as the Euler-Lagrange equation of Lagrangian <span class="math inline">\(\mathcal{L} = e^{\frac{t}{m}}(\frac{m}{2}||\dot{X}||^2 - f(X))\)</span></p>
<h2 id="whats-more">What's More?</h2>
<p>Recommend to read:</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://agustinus.kristia.de/techblog/2019/02/22/optimization-riemannian-manifolds/">Kristiadi's Blog</a></p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/optimization-gradient-methods/" rel="tag"># optimization, gradient methods</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/01/30/Rust-Notes/" rel="prev" title="Rust Notes">
      <i class="fa fa-chevron-left"></i> Rust Notes
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/02/06/gd2/" rel="next" title="Optimization II - Acceleration in Gradient Descent">
      Optimization II - Acceleration in Gradient Descent <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#perspectives-on-gradient-descent"><span class="nav-number">1.</span> <span class="nav-text">Perspectives on Gradient Descent</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#problem-formulation"><span class="nav-number">1.1.</span> <span class="nav-text">Problem Formulation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#proximal-view"><span class="nav-number">1.2.</span> <span class="nav-text">Proximal View</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#geometry-view"><span class="nav-number">1.3.</span> <span class="nav-text">Geometry View</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dynamic-view"><span class="nav-number">1.4.</span> <span class="nav-text">Dynamic View</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#whats-more"><span class="nav-number">1.5.</span> <span class="nav-text">What&#39;s More?</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yilin Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Happylinzy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Happylinzy" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://leetcode.com/yilin7616/" title="LeetCode → https:&#x2F;&#x2F;leetcode.com&#x2F;yilin7616&#x2F;" rel="noopener" target="_blank"><i class="fa fa-code fa-fw"></i>LeetCode</a>
      </span>
      <span class="links-of-author-item">
        <a href="/yilin7616@gmail.com" title="E-Mail → yilin7616@gmail.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/yilin-zhang-813854261/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;yilin-zhang-813854261&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.kaggle.com/ylinzh" title="Kaggle → https:&#x2F;&#x2F;www.kaggle.com&#x2F;ylinzh" rel="noopener" target="_blank"><i class="fab fa-kaggle fa-fw"></i>Kaggle</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yilin Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
