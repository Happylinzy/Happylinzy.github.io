<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"happylinzy.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Perspectives on Accelerated Gradient Descents Last post we talk about several different perspectives on gradient descent. It seems that gradient descent(GD) is a fairly useful algorithm to numerically">
<meta property="og:type" content="article">
<meta property="og:title" content="Optimization II - Acceleration in Gradient Descent">
<meta property="og:url" content="https://happylinzy.github.io/2023/02/06/gd2/index.html">
<meta property="og:site_name" content="Yilin Blog">
<meta property="og:description" content="Perspectives on Accelerated Gradient Descents Last post we talk about several different perspectives on gradient descent. It seems that gradient descent(GD) is a fairly useful algorithm to numerically">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-02-07T05:36:16.000Z">
<meta property="article:modified_time" content="2023-09-27T04:27:43.731Z">
<meta property="article:author" content="Yilin Zhang">
<meta property="article:tag" content="optimization">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://happylinzy.github.io/2023/02/06/gd2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Optimization II - Acceleration in Gradient Descent | Yilin Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Yilin Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://happylinzy.github.io/2023/02/06/gd2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yilin Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yilin Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Optimization II - Acceleration in Gradient Descent
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-02-06 21:36:16" itemprop="dateCreated datePublished" datetime="2023-02-06T21:36:16-08:00">2023-02-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-09-26 21:27:43" itemprop="dateModified" datetime="2023-09-26T21:27:43-07:00">2023-09-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/math/" itemprop="url" rel="index"><span itemprop="name">math</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="perspectives-on-accelerated-gradient-descents">Perspectives on Accelerated Gradient Descents</h1>
<p>Last post we talk about several different perspectives on gradient descent. It seems that gradient descent(GD) is a fairly useful algorithm to numerically solve optimization problem. However, things may become impractical when it comes to reality. One major problem is the convergence rate.</p>
<span id="more"></span>
<p>The gradient method is strictly decreasing. The nuw value of <span class="math inline">\(f\)</span> is always less or equal to the previous value. <span class="math display">\[
f(x_{k+1}) - f(x_k) \le 0
\]</span> However, this property is not necessary for an iteration algorithm to converge to its minimum. So what's the limits of first order algorithm? It has been proved by Nesterov that the best convergence rate of first order algorithm on a function <span class="math inline">\(f\)</span> is <span class="math inline">\(O(\frac{1}{k^2})\)</span>. Here I omit some parameters depending on the smoothness of function <span class="math inline">\(f\)</span>. If you are more interested in the details, please refer to <a target="_blank" rel="noopener" href="http://awibisono.github.io/2016/06/20/accelerated-gradient-descent.html">Wibisono's Blog</a>.</p>
<p>To improve the convergence rate of GD, mathematicians have come up with several acceleration descent algorithms. The heave-ball and Nesterov accelaration are the best among all these algorithms.</p>
<p><strong>The Heavy-Ball method(hv-ball):</strong> <span class="math display">\[
\begin{align*}
    x_{k+1} = x_k + \alpha (x_k - x_{k-1}) - s\nabla f(x_k)
\end{align*}
\]</span></p>
<p><strong>Nesterov method: NAG-c</strong> <span class="math display">\[
\begin{align*}
    y_{k+1} &amp;= x_k - s\nabla f(x_k)
    \\
    x_{k+1} &amp;= y_{k+1} + \frac{k}{k+3} (y_{k+1} - y_{k})
\end{align*}
\]</span></p>
<p><strong>Nesterov method: NAG-sc</strong> <span class="math display">\[
\begin{align*}
    y_{k+1} &amp;= x_k - s\nabla f(x_k)
    \\
    x_{k+1} &amp;= y_{k+1} + \frac{1-\sqrt{\mu s}}{1+\sqrt{\mu s}} (y_{k+1} - y_{k})
\end{align*}
\]</span></p>
<p>Still today researchers are studying about why these methods, with 'carefully' chosen parameters, can achieve acceleration than GD. In this post, I would like to introduce some excellent works done by researchers trying to find the secret behind first order gradient acceleraition.</p>
<h2 id="polynomial-view">Polynomial View</h2>
<p>I know the subtitle - "polynomial view" may seem confusing. But it does happen that the form of acceleration descent can be derived by Chebyshev polynomials. This work is shown in <a target="_blank" rel="noopener" href="http://blog.mrtz.org/2013/09/07/the-zen-of-gradient-descent.html">Hardt's Blog</a></p>
<p>In this blog, it shows us that the fastest first order gradient method to minimize a quadratic optimization problem can be derived by chebyshev polymoial. <span class="math display">\[
\min f(x) = \frac{1}{2}x^TAx -bx
\]</span> In quadratic form question, we can write <span class="math inline">\(x_k\)</span> explictly as a function operating on <span class="math inline">\(x_0\)</span>. Then we try to find the best funtion to minimize the residual between optimal and <span class="math inline">\(x_k\)</span>. After proper calculation, it turns out the Chebyshev polynomials just fits all requirements. Finally, the acceleration form is derived as <span class="math display">\[
x_{k+1} = x_k - \alpha_{k+1} \nabla f(x_k) + \beta_{k+1} \nabla f(x_{k-1}).
\]</span></p>
<p>My explanation here is rough and careless. Please refer to original blog for detailed information.</p>
<h2 id="dual-coupling-view">Dual Coupling View</h2>
<p>In this subsection, I would like to introduce works that interpretes acceleration phenomenon as the linear coupling of gradient descent and mirror descent. This work is done in <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1407.1537.pdf%5D">Linear Coupling: An Ultimate Unification of Gradient and Mirror Descent</a>.</p>
<p>In this paper, it mentions the thought under this coupling. For each step, the descent direction is closely related to the magnitute of <span class="math inline">\(||\nabla f(x)||_2\)</span>. When this entity is large, we conduct gradient descent. When it is small, we conduct mirror descent. Under this thought, Zhu combine two descent methods and achieve the convergence rate of Nesterov method.</p>
<h2 id="variational-view">Variational View</h2>
<p>A variational perspective to unify gradient methods as the Euler-Lagrange equation of a Lagrangian is done by Andre Wibisono in paper <a target="_blank" rel="noopener" href="https://www.pnas.org/doi/pdf/10.1073/pnas.1614734113">A variational perspective on accelerated methods in optimization</a>.</p>
<p>In this paper, it proposes a Bregman Lagrangian. By calculating the stationary point of this functional, we can get a second order ODE with multiple parameters. Then as we choose these parameters properly, we can derive Nesterov, gradient descent and several other methods.</p>
<p><span class="math display">\[
\mathcal{L}(X,V,t) = e^{\alpha_t + \gamma_t}(D_h(X+e^{\alpha_t}V, X) - e^{\beta_t}f(X))
\]</span></p>
<h2 id="dynamics-view">Dynamics View</h2>
<p>The study of acceleration dynamics are hot. These papers have proposed several different differential equations and provide their explanations.</p>
<p><strong>Paper I</strong> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1503.01243.pdf">A Differential Equation for Modeling Nesterov's Accelerated Gradient Method: Theory and Insights</a></p>
<p>This paper raises the differential equation for NAG-c as <span class="math display">\[
 \ddot{X} + \frac{3}{t}\dot{X} + \nabla f(X) = 0
\]</span> It explains the special status of constant "3" in the equation. Also, this work inspires the variational view on Nesterov acceleration.</p>
<p><strong>Paper II</strong> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.07436.pdf">A Dynamical Systems Perspective on Nesterov Acceleration</a></p>
<p>This paper raises the differential equation for Nesterov acceleration as <span class="math display">\[
\ddot{X} + 2d\dot{X} + \frac{1}{L\gamma^2}\nabla f(X + \beta \dot{X}) = 0
\]</span></p>
<p><strong>Paper III</strong> <a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s10107-021-01681-8">Understanding the acceleration phenomenon via high-resolution differential equations</a></p>
<p>This paper studies the difference between hv-ball, NAG-sc, NAG-c. Compared to previous two papers, it has reverse <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> value pairs. There is an extra "gradient correction" term in NAG methods to achieve more acceleration.</p>
<h2 id="whats-more">What's More?</h2>
<p>Recommend to read:</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://awibisono.github.io/">Wibisono's Blog</a></p>
<p><a target="_blank" rel="noopener" href="http://blog.mrtz.org/2013/09/07/the-zen-of-gradient-descent.html">Hardt's Blog</a></p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/optimization/" rel="tag"># optimization</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/02/04/gd1/" rel="prev" title="Optimization I - Gradient Descent">
      <i class="fa fa-chevron-left"></i> Optimization I - Gradient Descent
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/02/13/gd3/" rel="next" title="Optimization III - Statistical Manifold and Natural Gradient Descent">
      Optimization III - Statistical Manifold and Natural Gradient Descent <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#perspectives-on-accelerated-gradient-descents"><span class="nav-number">1.</span> <span class="nav-text">Perspectives on Accelerated Gradient Descents</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#polynomial-view"><span class="nav-number">1.1.</span> <span class="nav-text">Polynomial View</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dual-coupling-view"><span class="nav-number">1.2.</span> <span class="nav-text">Dual Coupling View</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#variational-view"><span class="nav-number">1.3.</span> <span class="nav-text">Variational View</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dynamics-view"><span class="nav-number">1.4.</span> <span class="nav-text">Dynamics View</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#whats-more"><span class="nav-number">1.5.</span> <span class="nav-text">What&#39;s More?</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yilin Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Happylinzy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Happylinzy" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://leetcode.com/yilin7616/" title="LeetCode → https:&#x2F;&#x2F;leetcode.com&#x2F;yilin7616&#x2F;" rel="noopener" target="_blank"><i class="fa fa-code fa-fw"></i>LeetCode</a>
      </span>
      <span class="links-of-author-item">
        <a href="/yilin7616@gmail.com" title="E-Mail → yilin7616@gmail.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/yilin-zhang-813854261/" title="Linkedin → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;yilin-zhang-813854261&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>Linkedin</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.kaggle.com/ylinzh" title="Kaggle → https:&#x2F;&#x2F;www.kaggle.com&#x2F;ylinzh" rel="noopener" target="_blank"><i class="fab fa-kaggle fa-fw"></i>Kaggle</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yilin Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
