---
title: Optimization IV - On Dynamics of Acceleration, Einstein, Rao and Nesterov
date: 2023-02-18 21:17:09
tags: math, physic, information geometry, general relativity
categories: math
mathjax: true
---
# On Dynamics of Acceleration, Einstein, Rao and Nesterov

If someone asks what's the most beautiful theory in physic, nobody would refuse **The Theory** of everything. Of course, this post can not establish a theory to explain everything. What I am trying to do here is to use general relativity to explain the dynamics of gradient methods.

<!-- more -->

Methods that can be interpreted in this framework includes gradient descent(GD), heavy-ball mehthod (HVB), Nesterov acceleration (NAG-sc, NAG-c), natural gradient descent(NGD), bregman mirror descent(BMD) and Newton's method(NM). Wow! It sounds like a BIG work. But actually just some calculation. Where should we start? Let's start with geodesic.

## Geodesic Equation on Manifold
Given a Riemannian manifold $\mathcal{M}$ with a metric tensor $g$, the length of a curve $\gamma : [a, b] \rightarrow \mathcal{M}$ is explicitly calculated as 
$$
l = \int_a^b \sqrt{g_{\gamma (\tau)}(\dot{\gamma}(\tau), \dot{\gamma}(\tau))} d\tau.
$$
The geodesic between two points $x$ and $y$ on manifold is defined as the infimum of all distance. Consider a curve with $\gamma(a) = x, \gamma(b) = y$. Then the geodesic between $x$ and $y$ satisfy the equation
$$
\delta l = 0 \Leftrightarrow \delta \int_a^b \sqrt{g_{\gamma (\tau)}(\dot{\gamma}(\tau), \dot{\gamma}(\tau))} d\tau = 0.
$$
By solving the variational equation we can get the geodesic equation on manifold as 
$$
\frac{d^2 x^{\mu}}{d \tau^2} + \Gamma^{\mu}_{v\lambda}\frac{d x^v}{d \tau} \frac{d x^\lambda}{d \tau} = 0.
$$
Here the $\Gamma^{\mu}_{v\lambda}$ is $\textit{Christoffel symbols of the second kind}$. Now we have the geodesic function defined on a Riemannian manifold. We put this aside and see why general relativity relates to Newton's equation.

## Newton's Limit of Geodesic Equation
In a four dimensional space, $\mathbb{R}^3$ spatial and $\mathbb{R}$ temporal, the motion of a particle under only gravity is described by geodesic equation. In the Newtonian limit, we have three assumptions: slow, static, weak. 

> "slow" means the 0-th component $x^0$ dominates other components. The $x^0$ here is just time $t$.
>
> "static" means that field does not change with time. Then $g$ is invariant to $t$.
>
> "weak" means the field is weak. It can be approximated by minkowski metric $\eta$.

Then here we show how to derive the Newton equation from geodesic equatin.
First, we consider slow motion, which means that the time scale is significant, $|\frac{d x^i}{d \tau}| \ll \frac{d t}{d \tau}$. The geodesic function turns to be
$$
\frac{d^2 x^{\mu}}{d \tau^2} + \Gamma^{\mu}_{00}\frac{d x^0}{d \tau} \frac{d x^0}{d \tau} = 0
$$
The possible values of $\mu$ are $\mu = 0,1,2,3$. The Christoffel symbols $\Gamma^{\mu}_{00}$ is
$$
\Gamma^{\mu}_{00} = \frac{1}{2} g^{\mu v}(\frac{\partial g_{v 0}}{\partial x^0} + \frac{\partial g_{0v}}{\partial x^0} - \frac{\partial g_{00}}{\partial x^v}).
$$
As the metric $g$ is invariant to time $t$, the first two items $\frac{\partial g_{v 0}}{\partial x^0}$ and $\frac{\partial g_{0 v}}{\partial x^0}$ are all 0. Therefore, the geodesic function is 
$$
\frac{d^2 x^{\mu}}{d \tau^2} - \frac{1}{2} g^{\mu v}(\frac{\partial g_{00}}{\partial x^v})(\frac{d x^0}{d \tau} )^2= 0.
$$
Since the gravity is weak, $g = \eta$, when $\mu = 0$, we have $g^{\mu v}(\frac{\partial g_{00}}{\partial x^v}) = 0$. When $\mu = 0$ we get
$$
\frac{d^2 x^0}{d \tau^2} =0 \Rightarrow x^0 = c \tau + d.
$$
Take $c = 1, d = 0$ we have $t = x^0 = \tau$. Then the geodesic equation turns to be
$$
\frac{d^2 x^{\mu}}{d t^2} - \frac{1}{2} \eta^{\mu v}(\frac{\partial g_{00}}{\partial x^v})= 0.
$$
Next when $\mu = 1, 2, 3$, the geodesic equation is formulated as 
$$
\frac{d^2 x^{\mu}}{d t^2} = \frac{1}{2} \frac{\partial g_{00}}{\partial x^{\mu}}.
$$
We can pile three equations together by leting $X = [x^1, x^2, x^3]^T$:
$$
\frac{d^2 X}{d t^2} = \frac{1}{2} \nabla g_{00}
$$
With proper choice of $X$, this form is identical to motion of a particle under potential
$$
m \frac{d^2 X}{d t^2} = -\nabla f(X).
$$
Where $X$ represents position and $f$ is potential function.

## Dully Flat Structure of Bregman Statistical Manifold
Given a strictly convex function $h \in C^3$, the Bregman divergence $B_h$ is defined as
$$
    B_h(x, y) = h(x) - h(y) - \langle \nabla h (y), x - y  \rangle
$$

Then if we consider that $x \in \mathcal{M}$, and the distance between two points $x, y$ as $B_h(y,x)$. Then the Riemannian metric and Levi-Civita connection generated by $B_h$ is 
$$
g = \nabla^2 h(x)
\\
\Gamma^{\mu}_{\gamma \lambda} = \frac{1}{2} g^{\mu v}(\frac{\partial g_{v \lambda}}{\partial x^\gamma} + \frac{\partial g_{v \gamma}}{\partial x^\lambda} - \frac{\partial g_{\gamma \lambda}}{\partial x^v}).
$$ 

The convex conjugate of $h$ is defined as 
$$
h^*(\theta) = \underset{x \in \mathcal{M}}{\sup} \{ \langle x, \theta \rangle - h(x) \}.
$$
This yeilds a dual coordinate system as 
$$
    \theta = \nabla h(x), x = \nabla h^*(\theta), \nabla^2 h(x) \nabla^2h^*(\theta) = I.
$$
The a dual Bregman divergence is defined as $B_{h^*}(\theta, \eta) = h^*(\theta) - h^*(\eta) - \langle \nabla h^*(\eta), \theta - \eta \rangle$. The connection between $B_h$ and $B_{h^*}$ is 
$$
    B_h(x, y) = B_{h^*}(\eta, \theta), \theta = \nabla h(x), \eta = \nabla h(y).
$$
In this case, the $B_{h^*}$ also generate a geometric structure on $\mathcal{M}$. It can be proved that the information manifold $\mathcal{M}$ is dually flat.

## Geodesic Equation on Bregman Statistical Manifold
In differential geometry, the geodesic is defined by affine connection $\nabla$. Similarly, for the information manifold with geometry structure generated by Bregman divergence $B_{h}$, there exist two dual affine connections $\nabla, \nabla^*$. This means that there exists two geodesic connecting two points between $P,Q$ on manifold. One geodesic is straight in $x$ coordinate, the other is straight in $\theta$ coordinate.

Next we consider a manifold $\mathcal{M}' = \mathbb{R} \times \mathcal{M}$ as $X = [t, x], x \in \mathcal{M}$. In this $\mathcal{M}'$ we have the Riemannian metric defined as 
$$
g = \left[
        \begin{array}{cc}
            g_{00} & 0 \\ 
            0 & \nabla^2 h(x)
        \end{array}
    \right]
\quad
g^{-1} = 
\left[
        \begin{array}{cc}
            1/g_{00} & 0 \\ 
            0 & \nabla^2 h(x)^{-1}
        \end{array}
    \right]
$$

Now consider the geodesic equation in $\mathcal{M}'$ coordinate:
$$
\frac{d^2 X^{\mu}}{d \tau^2} + \Gamma^{\mu}_{\gamma \lambda}\frac{d X^\gamma}{d \tau} \frac{d X^\lambda}{d \tau} = 0.
$$
We repeat the procedure by considering "slow" motion of particle under "static" field. By "slow" we have $|\frac{dX^i}{d \tau}| \ll \frac{dX^0}{d \tau}$. By "static" we have $\frac{\partial g}{\partial X^0} = 0$ This leads to
$$
\frac{d^2 X^{\mu}}{d \tau^2} +\Gamma^{\mu}_{00} (\frac{d X^0}{d \tau})^2 = 0
\\
\frac{d^2 X^{\mu}}{d \tau^2} - \frac{1}{2} g^{\mu v}(\frac{\partial g_{00}}{\partial X^v})(\frac{d X^0}{d \tau} )^2= 0.
$$
When $\mu = 0$, since $\frac{\partial g_{00}}{\partial X^0} = 0$, we get
$$
\frac{d^2 X^{0}}{d \tau^2} = 0
$$
Solve it gives $t = c_1 \tau + c_2$. With out loss of generality, we select $c_1 = 1, c_2 = 0$ and the $t = \tau$.

Now we consider $\mu = 1, ..., n$. With $t = \tau$ we have
$$
\frac{d^2 X^{\mu}}{d t^2} - \frac{1}{2} g^{\mu v}(\frac{\partial g_{00}}{\partial X^v})= 0
\\
\frac{d^2 X^{\mu}}{d t^2} - \sum_{v = 1}^{n}\frac{1}{2} g^{\mu v}(\frac{\partial g_{00}}{\partial X^v})= 0
$$
Pile $n$ equations we get
$$
 \frac{d^2}{d t^2}
 \left[
    \begin{array}{c}
        X^1\\
        \vdots \\
        X^n
    \end{array}
 \right]
 = \frac{1}{2}
  \left[
    \begin{array}{ccc}
        g^{11} & \cdots & g^{1n}\\
        \vdots & \ddots & \vdots \\
        g^{n1} & \cdots & g^{nn}
    \end{array}
 \right]
 \left[
    \begin{array}{c}
        \frac{\partial g_{00}}{\partial X^1}\\
        \vdots \\
        \frac{\partial g_{00}}{\partial X^n}
    \end{array}
 \right]
\\
\Leftrightarrow \ddot{x} = \frac{1}{2}\nabla^2 h(x)^{-1} \nabla g_{00}
$$
By taking $g_{00} = -2f(x)$ we get that
$$
\ddot{x} = -\nabla^2 h(x)^{-1} \nabla f(x)
$$

## Flows of Gradient Methods
With the above konwledge, now we know the approximation of geodesic equation under the slow, static assumption. The equation $\ddot{x} = \nabla^2 h(x)^{-1} \nabla f(x)$ describes the physic law that particle must follow. Now consider a geodesic between point $x_0$ and $x^*$. We assume that there exists a particle $p$ with mass $m=1$ moving along the geodesic from $t$ to $t + \Delta t$ where $x(t) = x_0, \dot{x}(t) = 0$.

Then we have the following equation to calculate the velocity of $p$ at $t + \Delta t$:
$$
\frac{d}{dt}x(t + \Delta t) = -\nabla^2 h(x)^{-1} \int_t^{\Delta t} \nabla f(x) dt
$$
where $\nabla^2 h(x)^{-1}$ is not related to time because static assumption.
From mean value theorem we know that $\exists \Delta t' \in (0, \Delta t)$ such that 
$$
\int_t^{t + \Delta t} \nabla f(x) dt = \Delta t\nabla f(x(t+\Delta t'))
$$

The Taylor series approximation of LHS and RHS is that 
$$
        \dot{x}(t + \Delta t) = \dot{x}(t) + \Delta t \ddot{x}(t) + O((\Delta t)^2)
\\
        \nabla f(x(t+\Delta t')) = \nabla f(x(t)) + \Delta t' \nabla^2 f(x(t))\dot{x}(t) + O((\Delta t')^2).
$$
Then we get the approximation equation of the motion as below:
$$
\dot{x}(t) + \Delta t \ddot{x}(t) + O((\Delta t)^2) = -\Delta t\nabla^2 h(x)^{-1}(\nabla f(x(t)) + \Delta t' \nabla^2 f(x(t))\dot{x}(t) + O((\Delta t')^2))
$$
This equation describes the flows of gradient based methods. 

If we take $O((\Delta t)^2)$ and $O((\Delta t')^2)$ accuracy we get
$$
\Rightarrow
\frac{d}{dt}(x + \Delta t \dot{x}) = -\Delta t \nabla^2 h(x)^{-1}(\nabla f(x) + \Delta t' \nabla^2 f(x)\dot{x}).
$$

If we take $O((\Delta t)^2)$ and $O(\Delta t')$ accuracy we get
$$
\Rightarrow
\frac{d}{dt}(x + \Delta t \dot{x}) = -\Delta t \nabla^2 h(x)^{-1}\nabla f(x).
$$

If we take $O(\Delta t)$ and $O(\Delta t')$ accuracy we get
$$
\Rightarrow
\frac{d}{dt}x = -\Delta t \nabla^2 h(x)^{-1}\nabla f(x)
$$

## Approximation and Discretizaiton
Finally after some calculation we get some differential equations. Next I would like to show how to connect these equations with gradient methods. With proper choice of $h$, the term $\nabla^2 h(x)$ turns to be Fisher matrix, scalar or $\nabla^2 f$.

### Gradient Based Methods

#### Gradient Descent
$$\begin{equation}
   \fbox{
    $x_{k+1} = x_{k} - \alpha \nabla f(x_k)$
    }
\end{equation}$$

#### Newton's Descent
$$\begin{equation}
    \fbox{
    $x_{k+1} = x_k - \alpha \nabla^2 f(x_k)^{-1} \nabla f(x_k)$
    }
\end{equation}$$

#### Natural Gradient Descent
$$ \begin{equation}
   \fbox{
    $    x_{k+1} = x_{k}  - \alpha F(x_k)^{-1}\nabla f(x_k).$
    }
\end{equation}$$

#### Heavy-Ball Method
$$
\begin{equation}
   \fbox{
    $x_{k+1} = x_{k} -  s \nabla f(x_k) + \alpha (x_k - x_{t-1})$
    }
\end{equation}
$$

#### Nesterov Gradient Methods
the Nesterov gradient methods (NAG-sc) is defined as 
$$\begin{equation}
    \begin{aligned}
        y_{k+1} & = x_k - s\nabla f(x_k),
\\
        x_{k+1} & = y_{k+1} + \frac{1-\sqrt{\mu s}}{1+\sqrt{\mu s}}(y_{k+1} - y_{k})
    \end{aligned}
\end{equation}$$

For a weakly convex function, we have (NAG-c) as:
$$\begin{equation}
    \begin{aligned}
        y_{k+1} &= x_{k} - \alpha\nabla f(x_{k}), 
        \\ 
        x_{k+1} &= y_{k+1} + \frac{k}{k+3}(y_{k+1} - y_{k}).
    \end{aligned}
\end{equation}$$

### Flow Derivation
Here are some basic notations for flow derivation. First, we take $x_k = X_{\delta k} = X_t$, where $\delta$ is the step size.
This means that $x_k$ is sampled from flow of $X_t$ with step size $\delta$.

Then we have the following Talyor series:
$$\begin{equation*}
    \begin{aligned}
        x_{k+1} &= X_{k\delta + \delta} = X_{t+\delta} = X_t + \dot{X_t}\delta + \frac{\ddot{X_t}}{2}\delta^2 + O(\delta^3)
        \\
        x_{k-1} &= X_{k\delta - \delta} = X_{t-\delta} = X_t - \dot{X_t}\delta + \frac{\ddot{X_t}}{2}\delta^2 + O(\delta^3)
        \\
        \nabla f(x_{k-1}) &= \nabla f(X_{k\delta - \delta}) = \nabla f(X_{t - \delta}) = \nabla f(X_t) - \delta \nabla^2f(X_t)\dot{X_t} + O(\delta^2)
    \end{aligned}
\end{equation*}$$

#### Gradient Flow
From the discretization $x_{k+1} = x_k - \alpha \nabla f(x_k)$ we have that
$$\begin{equation*}
    \begin{aligned}
       & x_{k+1} - x_k  = - \alpha \nabla f(x_k)
\\ 
\Leftrightarrow & \dot{X_t}\delta  + O(\delta^2) = -\alpha \nabla f(X_t)
\\
\Leftrightarrow &   \dot{X_t}\delta + \alpha \nabla f(X_t) = 0
    \end{aligned}
\end{equation*}$$
Take $\delta$ as scale $\delta = \alpha$.
$$\begin{equation*}
    \begin{aligned}
\Rightarrow \frac{d}{dt}X_t = -\nabla f(X_t)
    \end{aligned}
\end{equation*}$$

#### Newton's Flow
$$
\frac{d}{dt}X_t = - \nabla^2 f(X_t) \nabla f(X_t)
$$

#### Natural Gradient Flow
$$
\frac{d}{dt}X_t = - F(X_t)^{-1} \nabla f(X_t)
$$

#### Heavy Ball Flow
From the discretization $x_{k+1} = x_{k} - s \nabla f(x_k) + \alpha (x_k - x_{k-1})$ we have that
$$\begin{equation*}
    \begin{aligned}
                &x_{k+1} -  x_{k} =\alpha (x_k - x_{k-1}) - s \nabla f(x_k)
\\
\Leftrightarrow \ & \dot{X_t}\delta + \frac{\ddot{X_t}}{2}\delta^2 + O(\delta^3) = \alpha(\dot{X_t}\delta - \frac{\ddot{X_t}}{2}\delta^2 + O(\delta^3)) -s\nabla f(X_t) + O(\delta^3)
\\
\Leftrightarrow \ & \frac{\delta^2(1+\alpha)}{2}\ddot{X_t} + (1-\alpha)\delta\dot{X_t} + s \nabla f(X_t) + O(\delta^3) = 0
\\
\Leftrightarrow \ & \delta^2\ddot{X_t} + \frac{2(1-\alpha)}{1+\alpha}\delta\dot{X_t} + \frac{2s}{1+\alpha} \nabla f(X_t) + O(\delta^3) = 0
    \end{aligned}
\end{equation*}$$
Now we can derive that the scale of $\delta$ is the same as $\sqrt{s}$, which leads to
$$\begin{equation*}
    \begin{aligned}
                & \ddot{X_t} + \frac{2(1-\alpha)}{\sqrt{s}(1+\alpha)}\dot{X_t} + \frac{2}{1+\alpha} \nabla f(X_t) = 0
\\
\Leftrightarrow \ & \ddot{X_t} + 2\sqrt{\mu}\dot{X_t} + (1 + \sqrt{\mu s}) \nabla f(X_t) = 0, \alpha = \frac{1-\sqrt{\mu s}}{1+\sqrt{\mu s}}.
    \end{aligned}
\end{equation*}$$

If we take $\delta = \sqrt{\frac{2s}{1+\alpha}}$, the equation turns to be 
$$\begin{equation*}
    \begin{aligned}
        \ddot{X_t} + \frac{2(1-\alpha)}{(1+\alpha)}\sqrt{\frac{1+\alpha}{2s}}\dot{X_t} +  \nabla f(X_t) = 0
\\
\Rightarrow \frac{d}{dt}(X + \frac{(1+\alpha)}{2(1-\alpha)} \sqrt{\frac{2s}{1+\alpha}}\dot{X}) = - \frac{(1+\alpha)}{2(1-\alpha)} \sqrt{\frac{2s}{1+\alpha}}\nabla f(X_t)
    \end{aligned}
\end{equation*}$$

#### NAG-sc Flow
From the discretization that $y_{k+1} = x_k - s\nabla f(x_k), x_{k+1} = y_{k+1} + \frac{1-\sqrt{\mu s}}{1+\sqrt{\mu s}}(y_{k+1} - y_{k}).$ we have that
$$\begin{equation*}
    \begin{aligned}
                & x_{k+1} = x_{k} - s\nabla f(x_k) + \frac{1-\sqrt{\mu s}}{1+\sqrt{\mu s}} (x_k - s\nabla f(x_k) - x_{k-1} + s\nabla f(x_{k-1})) = 0
\\
\Leftrightarrow \ & x_{k+1} + x_{k-1} - 2x_{k} + \sqrt{\mu s}(x_{k+1} - x_{k-1}) = -(s - \sqrt{\mu} s^{\frac{3}{2}})(\nabla f(x_k) - \nabla f(x_{k-1})) - s(1+\sqrt{\mu s})\nabla f(x_k)
\\
\Leftrightarrow \ & \delta^2\ddot{X_t} + O(\delta^3) + \sqrt{\mu s}(2\delta\dot{X_t} + O(\delta^3)) = -(s - \sqrt{\mu} s^{\frac{3}{2}})(\delta \nabla^2 f(X_t)\dot{X_t} + O(\delta^2)) + s(1+\sqrt{\mu s})\nabla f(X_t)
\\
\Leftrightarrow \ & \delta^2\ddot{X_t} + 2\sqrt{\mu s}\delta\dot{X_t} + (s - \sqrt{\mu} s^{\frac{3}{2}})\delta \nabla^2 f(X_t)\dot{X_t} + s(1+\sqrt{\mu s})\nabla f(X_t) = 0
\\
\Leftrightarrow \ & \ddot{X_t} + 2\sqrt{\mu}\dot{X_t} + \sqrt{s} \nabla^2 f(X_t)\dot{X_t} + (1+\sqrt{\mu s})\nabla f(X_t) = 0
    \end{aligned}
\end{equation*}$$
If we take $\delta = \sqrt{s(1+\sqrt{\mu s})}$, then we get
$$\begin{equation*}
    \begin{aligned}
        \ddot{X_t} + 2\sqrt{\frac{\mu}{1+\sqrt{\mu s}}}\dot{X_t} + \sqrt{\frac{s}{1+\sqrt{\mu s}}} \nabla^2 f(X_t)\dot{X_t} + \nabla f(X_t) = 0
\\
\Rightarrow \frac{d}{dt} \left (X + \frac{1}{2}\sqrt{\frac{1+\sqrt{\mu s}}{\mu}}\dot{X} \right ) = - \frac{1}{2}\sqrt{\frac{1+\sqrt{\mu s}}{\mu}} \left (\nabla f(X_t) + \frac{s(1-\sqrt{\mu s})}{\sqrt{s(1+\sqrt{\mu s})}} \nabla^2 f(X)\dot{X} \right )
    \end{aligned}
\end{equation*}$$

####  NAG-c Flow
From the discretization that $y_{k+1} = x_{k} - \alpha\nabla f(x_{k}),  x_{k+1} = y_{k+1} + \frac{k}{k+3}(y_{k+1} - y_{k})$ we have that
$$\begin{equation*}
    \begin{aligned}
        &k(x_{k+1}+x_{k-1} - 2x_k) + 3(x_{k+1} - x_k) = -ks(\nabla f(x_k) - \nabla f(x_{k-1})) - s(k+3)\nabla f(x_k)
\\
\Rightarrow &k\delta^2\ddot{X_t} + 3(\delta \dot{X_t} + \frac{\delta^2}{2}\ddot{X_t}) = -ks\nabla^2 f(x)\dot{X_t} + s(k+3)\nabla f(X_t)
\\
\Rightarrow &(k\delta^2 + \frac{3\delta^2}{2})\ddot{X_t} + 3\delta\dot{X_t} + ks\nabla^2 f(x)\dot{X_t} + s(k+3)\nabla f(X_t) = 0
    \end{aligned}
\end{equation*}$$
Let $k\delta^2 + \frac{3\delta^2}{2} = s(k+3)$ we have
$$\begin{equation*}
    \begin{aligned}
\Rightarrow  &\ddot{X} + \frac{3}{\sqrt{s(k+3)(k+\frac{3}{2})}}\dot{X} + \frac{k\sqrt{s}}{\sqrt{(k+3)(k+\frac{3}{2})}}\nabla^2 f(X)\dot{X} + \nabla f(X) = 0
\\
\Rightarrow  &\frac{d}{dt}\left( X + \frac{\sqrt{s(k+3)(k+\frac{3}{2})}}{3}\dot{X} \right) = - \frac{\sqrt{s(k+3)(k+\frac{3}{2})}}{3}\left (\nabla f(X) + \frac{k\sqrt{s}}{\sqrt{(k+3)(k+\frac{3}{2})}} \nabla^2 f(X) \dot{X}\right )
    \end{aligned}
\end{equation*}$$

The above equations show how we derive different gradient methods from statistical manifold using general relativity.